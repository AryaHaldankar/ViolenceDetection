{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import imageio\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug as ia\n",
        "import math\n",
        "import random\n",
        "from keras.applications.resnet_v2 import preprocess_input\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "GLbGd3Xt81cU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocess the images and store them as labled data in csv file.**"
      ],
      "metadata": {
        "id": "6iZzLfHge64X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def video_to_frames(video):\n",
        "    vidcap = cv2.VideoCapture(video)\n",
        "    ids = set()\n",
        "    while len(ids) <= 4:\n",
        "      ids.add(random.randint(1, vidcap.get(cv2.CAP_PROP_FRAME_COUNT) - 1))\n",
        "\n",
        "    ImageFrames = []\n",
        "    for id in ids:\n",
        "      vidcap.set(cv2.CAP_PROP_POS_FRAMES, id - 1)\n",
        "      success, image = vidcap.read()\n",
        "\n",
        "      if success:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = preprocess_input(image)\n",
        "        ImageFrames.append(image)\n",
        "      else:\n",
        "        print('Failure!!!')\n",
        "\n",
        "    vidcap.release()\n",
        "\n",
        "    return ImageFrames"
      ],
      "metadata": {
        "id": "FqG0HF_J4bIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def get_all_file_paths(directory):\n",
        "    return [str(file) for file in Path(directory).rglob('*') if file.is_file()]\n",
        "\n",
        "# NonViolence\n",
        "paths_nonvi = []\n",
        "paths_vi = []\n",
        "for i in range(1, 6):\n",
        "  directory_nonvi = f'/content/drive/MyDrive/Violence Detection/data/violent_flow/movies/{i}/NonViolence'\n",
        "  directory_vi = f'/content/drive/MyDrive/Violence Detection/data/violent_flow/movies/{i}/Violence'\n",
        "  paths_nonvi.extend(get_all_file_paths(directory_nonvi))\n",
        "  paths_vi.extend(get_all_file_paths(directory_vi))"
      ],
      "metadata": {
        "id": "HMJXYeiECrEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "violence_frames = []\n",
        "non_violence_frames = []\n",
        "for path in paths_vi:\n",
        "  violence_frames.extend(video_to_frames(path))\n",
        "for path in paths_nonvi:\n",
        "  non_violence_frames.extend(video_to_frames(path))"
      ],
      "metadata": {
        "id": "WP3FRFDMULRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "violence_dataframe = pd.DataFrame({'image': violence_frames, 'y': np.ones(615, dtype = int)})\n",
        "non_violence_dataframe = pd.DataFrame({'image': non_violence_frames, 'y': np.zeros(615, dtype = int)})\n",
        "data = pd.concat([violence_dataframe, non_violence_dataframe], ignore_index = True)"
      ],
      "metadata": {
        "id": "he5Onkk5U5d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-Jj-CESEcdVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_data_numpy = shuffled_data.to_numpy()"
      ],
      "metadata": {
        "id": "RGLotMBSd_9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/Violence Detection/data.npy', shuffled_data_numpy)"
      ],
      "metadata": {
        "id": "dwO0GLA7k5wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer train the ResNet model**"
      ],
      "metadata": {
        "id": "R1G32A0YfSqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('/content/drive/MyDrive/Violence Detection/data.npy', allow_pickle = True)"
      ],
      "metadata": {
        "id": "vAcGdX7Fgvd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvkCzi338oXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b261cb-ea08-40f9-a919-79e993c3cdad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m234545216/234545216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = keras.applications.ResNet152V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    classifier_activation=\"softmax\",\n",
        "    name=\"resnet152v2\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "umdgR7W0m6-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.layers.Input(shape = (240, 320, 3))"
      ],
      "metadata": {
        "id": "Rf2HmCvOq0Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model(inputs, training = False)"
      ],
      "metadata": {
        "id": "AgykWT4ArJTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = keras.layers.GlobalAveragePooling2D()(x)"
      ],
      "metadata": {
        "id": "0UiifI8DsKjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = keras.layers.Dense(1, activation = 'sigmoid')(y)"
      ],
      "metadata": {
        "id": "01dnQYuprY20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "swpesg71rgVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "rYuBARRUrrw0",
        "outputId": "205843d7-988b-402b-9e6b-4b30a24d2eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m320\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet152v2 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2048\u001b[0m)         │      \u001b[38;5;34m58,331,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m2,049\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ resnet152v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">58,331,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m58,333,697\u001b[0m (222.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,333,697</span> (222.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,049\u001b[0m (8.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> (8.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m58,331,648\u001b[0m (222.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">58,331,648</span> (222.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[:, 0]\n",
        "y = data[:, 1]"
      ],
      "metadata": {
        "id": "sYEIqnEF1-qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped = np.array([row for row in x])"
      ],
      "metadata": {
        "id": "2dePvLA15adc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1K0VS75vVA",
        "outputId": "6f08cc96-cf47-434e-d547-a3557bd38b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1230, 240, 320, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_reshaped_tensor = tf.convert_to_tensor(x_reshaped)"
      ],
      "metadata": {
        "id": "9lgdhyF_6C-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_reshaped = np.array([row for row in y])"
      ],
      "metadata": {
        "id": "QjCXBRxd6I9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_reshaped_tensor = tf.convert_to_tensor(y_reshaped)"
      ],
      "metadata": {
        "id": "auLWOgl16ZSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_reshaped, y_reshaped, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "OZs6H9QnrtwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 6\n",
        "model.fit(x_train, y_train, epochs=epochs, batch_size = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UhLj9K12qqS",
        "outputId": "425e907a-4b4f-4cb9-91e3-67fe15d8f32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:707: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 547ms/step - binary_accuracy: 0.7266 - loss: 0.5487\n",
            "Epoch 2/6\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 254ms/step - binary_accuracy: 0.9037 - loss: 0.2555\n",
            "Epoch 3/6\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 256ms/step - binary_accuracy: 0.9321 - loss: 0.2077\n",
            "Epoch 4/6\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - binary_accuracy: 0.9596 - loss: 0.1467\n",
            "Epoch 5/6\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 286ms/step - binary_accuracy: 0.9742 - loss: 0.1214\n",
            "Epoch 6/6\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 271ms/step - binary_accuracy: 0.9879 - loss: 0.1020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c7903f991e0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Violence Detection/model.keras')"
      ],
      "metadata": {
        "id": "1grw5FxbOW-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, batch_size = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIRK8Tp1B8Wk",
        "outputId": "94f6bbd7-6f2f-4c45-dbd1-5049f02541aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - binary_accuracy: 0.9706 - loss: 0.1319\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13625501096248627, 0.9634146094322205]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to accept video and return how violent it is.**"
      ],
      "metadata": {
        "id": "8p5RyPmtKsmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path):\n",
        "  vidcap = cv2.VideoCapture(video_path)\n",
        "  frames = []\n",
        "  ids = set()\n",
        "  while len(ids) < 20:\n",
        "    ids.add(random.randint(1, vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "  for id in ids:\n",
        "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, id - 1)\n",
        "    success, image = vidcap.read()\n",
        "    if success:\n",
        "      image = cv2.resize(image, (320, 240))\n",
        "      image = preprocess_input(image)\n",
        "      frames.append(image)\n",
        "    else:\n",
        "      print('Failure!!!')\n",
        "  return np.array([row for row in frames])"
      ],
      "metadata": {
        "id": "FxbOs2LdLpnJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.ResNet152V2(\n",
        "    include_top=False,\n",
        "    weights=None,\n",
        "    classifier_activation=\"softmax\",\n",
        "    name=\"resnet152v2\",\n",
        ")\n",
        "inputs = keras.layers.Input(shape = (240, 320, 3))\n",
        "x = base_model(inputs)\n",
        "y = keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = keras.layers.Dense(1, activation = 'sigmoid')(y)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.load_weights('/content/drive/MyDrive/Violence Detection/model.keras')"
      ],
      "metadata": {
        "id": "4dkpKKlXSwNO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_violence(video_path):\n",
        "  processed_video = process_video(video_path)\n",
        "  outputs = model.predict(processed_video)\n",
        "  return outputs.mean()"
      ],
      "metadata": {
        "id": "lksA-3psWQ5c"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#non violent video 0 = non violent, 1 = violent\n",
        "print(video_violence('/content/drive/MyDrive/Violence Detection/data/violent_flow/movies/1/NonViolence/football_crowds__Giants_of_Brazil_6_of_6__anandaliyanage__lq-GBA34iEI.avi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqMtdIRpXdSm",
        "outputId": "0ef0f1ab-5199-44cb-a24b-db3d15e93e7d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step\n",
            "0.03976413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#violent video 0 = non violent, 1 = violent\n",
        "print(video_violence('/content/drive/MyDrive/Violence Detection/data/violent_flow/movies/1/Violence/Hooligans_violence__5x5_russian_hooligans_fight__Parkhom__GnfpwW6sMkc.avi'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhwsNgSybIuc",
        "outputId": "77287dbe-e626-46ab-b850-e96f308e8396"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
            "0.92524546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPtYkSyEbS8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}